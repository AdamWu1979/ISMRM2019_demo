{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grappa.ai - Run AI based recon in Gadgetron\n",
    "\n",
    "Welcome to the Grappa.ai demo. This demo is developed as a part of [Gadgetron](https://github.com/gadgetron/gadgetron) ISMRM 2019 software demo session.\n",
    "\n",
    "This demo is to show you how to implement an AI based MR reconstruction model and deploy it into Gadgetron recon chain. \n",
    "\n",
    "This example (I call it **Grappa.ai**) aims to demonstrate how to write a python function to implemant a MR recon with [PyTorch](https://pytorch.org/) and call the recon inside a Gadgetron chain.\n",
    "\n",
    "**Author**: `Hui Xue <hui.xue@nih.gov>`\n",
    "\n",
    "**National Heart Lung and Blood Institute (NHLBI),**\n",
    "**National Institutes of Health,**\n",
    "**Bethesda, Maryland, US**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pytorch and other libraries\n",
    "\n",
    "To install Pytorch:\n",
    "```\n",
    "sudo pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
    "sudo pip3 install torchvision\n",
    "```\n",
    "\n",
    "or if you have GPU:\n",
    "```\n",
    "sudo pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
    "```\n",
    "\n",
    "To install ismrmrd python and ismrmrd python-tool:\n",
    "```\n",
    "cd ~/software\n",
    "git clone git@github.com:ismrmrd/ismrmrd-python.git\n",
    "cd ismrmrd-python\n",
    "sudo python3 setup.py install\n",
    "\n",
    "git clone git@github.com:ismrmrd/ismrmrd-python-tools.git\n",
    "cd ismrmrd-python-tools\n",
    "sudo python3 setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as spio\n",
    "import copy\n",
    "\n",
    "import ismrmrd\n",
    "import ismrmrdtools\n",
    "from ismrmrdtools import show, simulation, transform\n",
    "from ismrmrdtools import coils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether we have GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get environment variables for Gadgetron\n",
    "\n",
    "This demo requires the installation of Gadgetron. The enviornment variable **GADGETRON_HOME** points to the directory where Gadgetron is installed.\n",
    "The Gadgetron python path should be added to Python sys search path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get Gadgetron home\n",
    "gt_home = os.getenv('GADGETRON_HOME')\n",
    "print(\"Gadgetron is installed at \", gt_home)\n",
    "\n",
    "# get Gadgetron folder for python scripts\n",
    "gt_py_home = os.path.join(gt_home, 'share/gadgetron/python')\n",
    "print(\"Gadgetron Python scripts are installed at \", gt_py_home)\n",
    "\n",
    "# insert Gadgetron python folder to python sys path\n",
    "sys.path.insert(0, gt_py_home)\n",
    "\n",
    "# path to store test data\n",
    "gt_data_home = os.path.join(os.getcwd(), 'data')\n",
    "print(\"Test data is at \", gt_data_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions for AI MR Recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_2_real(a):\n",
    "    \"\"\"\n",
    "    Convert a data matrix from complex to real and imag array\n",
    "    \"\"\"\n",
    "    a_r = np.real(a)\n",
    "    a_i = np.imag(a)\n",
    "\n",
    "    D, NA = a_r.shape\n",
    "\n",
    "    res = np.zeros((D, 2*NA), dtype=np.float32)\n",
    "\n",
    "    res[:,0:NA] = a_r\n",
    "    res[:,NA:] = a_i\n",
    "    \n",
    "    return res\n",
    "\n",
    "def real_2_complex(a):\n",
    "    \"\"\"\n",
    "    Convert a real and imag data matrix to complex\n",
    "    \"\"\"\n",
    "    D, NA = a.shape\n",
    "\n",
    "    N = int(NA/2)\n",
    "    \n",
    "    res = a[:,0:N] + 1j * a[:,N:]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_array(im, columns=4, figsize=[32, 32], cmap='gray'):\n",
    "    \"\"\"Plot image array as a panel of images\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    plt.set_cmap(cmap)\n",
    "    \n",
    "    if(len(im.shape)==3):\n",
    "        RO, E1, N = im.shape\n",
    "    else:\n",
    "        RO, E1 = im.shape\n",
    "        N = 1\n",
    "\n",
    "    rows = np.ceil(N/columns)\n",
    "    for i in range(1, N+1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        if(len(im.shape)==3):\n",
    "            plt.imshow(im[:,:,i-1])\n",
    "        else:\n",
    "            plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load kspace data\n",
    "\n",
    "This test data is a phantom scan with R=3 acceleration. The matrix size 192x144 with 75% phase encoding resolution. THe readout is SSFP and ACE/ref data is 192x48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "data_dir = os.path.join(gt_data_home, 'meas_MID00349_FID09273_SNR_R3')\n",
    "data_name = os.path.join(data_dir, 'Grappa_test_data.mat')\n",
    "print(data_name)\n",
    "D = spio.loadmat(data_name)\n",
    "accelFactor = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_src = np.squeeze(D['ref_src'])\n",
    "ref_dst = np.squeeze(D['ref_dst'])\n",
    "data = np.squeeze(D['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('ref_src = ', ref_src.shape, np.linalg.norm(ref_src))\n",
    "print('ref_dst = ', ref_dst.shape, np.linalg.norm(ref_dst))\n",
    "print('data = ', data.shape, np.linalg.norm(data))\n",
    "\n",
    "refRO, refE1, dstCHA = np.squeeze(ref_dst).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data for first 8 channels\n",
    "res = plot_image_array(np.log(np.abs(data[:,:,0:8])+1e-8), 8, [32,32], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ACS data for first 8 channels\n",
    "res = plot_image_array(np.abs(ref_src[:,:,0:8]), 8, [16, 16], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the coil map\n",
    "res = plot_image_array(np.abs(csm), 8, [16, 16])\n",
    "res = plot_image_array(np.angle(csm), 8, [16, 16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grappa recon\n",
    "\n",
    "Let's first perform a Grappa reconstruction by calling the Gadgetron python wrapper for Grappa:\n",
    "\n",
    "This python wrapper is declared at ${GADGETRON_DIR}\\toolboxes\\mri_core\\mri_core_grappa_python.h, which uses the [boost-python](https://www.boost.org/doc/libs/1_69_0/libs/python/doc/html/index.html) to wrap c++ functionality.\n",
    "\n",
    "Recall Grappa is to estimate kspace interpolation kernel to fill in unacquired phase encoding line: ![Grappa calibration process!](images/Grappa.png)\n",
    "\n",
    "All red points are acquired kspace data. These points are fitted to blud dots (missing data). For a kernel size of 5x4, the Grappa calibration equation can be assembled.\n",
    "\n",
    "After solving this linear system, the kernel is estimated from ACS data. Applying the kernel to imaging data is just another matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import Gadgetron grappa\n",
    "import gadgetron_toolbox_mri_core_python as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grappa = gt.grappa2D()\n",
    "\n",
    "kRO = 5 # kernel size along RO\n",
    "kNE1 = 4 # kernel size along first phase encoding\n",
    "fitItself = False # whether to fix green dot\n",
    "thres = 1e-4 # regularization for matrix inversion\n",
    "\n",
    "res = grappa.initialize(accelFactor, kRO, kNE1, fitItself, thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(fitItself):\n",
    "    grappa.calib(ref_src, ref_dst)    \n",
    "else:\n",
    "    grappa.calib(ref_src, ref_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data2D = data[:,:,:,0]\n",
    "    fullkspace = grappa.recon(data[:,:,:,0], True)\n",
    "except:\n",
    "    fullkspace = grappa.recon(data, True)\n",
    "    data2D = data\n",
    "    \n",
    "print(\"Reconstructed full kspace is \", fullkspace.shape)\n",
    "\n",
    "if(not fitItself):\n",
    "    fullkspace = fullkspace + data2D\n",
    "\n",
    "# convert to image domain\n",
    "im = transform.transform_kspace_to_image(fullkspace)\n",
    "\n",
    "# estimate coil map\n",
    "(csm_est2, rho2) = coils.calculate_csm_inati_iter(np.transpose(im, (2,0,1)))\n",
    "csm = np.transpose(csm_est2, (1,2,0))\n",
    "\n",
    "# coil combination\n",
    "im_combined = np.sum(im*np.conj(csm), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = plot_image_array(np.abs(im_combined), 1, [8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grappa reconstruction as numpy matrix multiplication\n",
    "\n",
    "The reconstrution process of Grappa is as follows:\n",
    "\n",
    "```\n",
    "for every kspace point in data:\n",
    "    1. Extract the 5x4xCHA acquired dataA\n",
    "    2. Multiply dataA with ker : res = np.dot(dataA, ker)\n",
    "        here ker is (5x4xCHA, 2xCHA)\n",
    "        res is (1, 2xCHA)\n",
    "    3. Fill res to the data array for missing data\n",
    "```\n",
    "\n",
    "In practise, we should assamble the dataA as a matrix (N, 5x4xCHA) and perform the matrix multiplication once.\n",
    "\n",
    "Gadgetron python grappa offers functions to return dataA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibration matrix A\n",
    "A = grappa.get_A()\n",
    "# calibration matrix A\n",
    "B = grappa.get_B()\n",
    "# estimated kernel\n",
    "ker = grappa.get_ker()\n",
    "print('A is ', A.shape)\n",
    "print('B is ', B.shape)\n",
    "print('ker is ', ker.shape)\n",
    "\n",
    "dataA = grappa.get_data_A()\n",
    "dataAInd = grappa.get_data_A_index()\n",
    "\n",
    "print('dataA = ', dataA.shape)\n",
    "print('dataAInd = ', dataAInd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kernel, how do they look?\n",
    "res = plot_image_array(np.abs(gt_ker[:,:,:,4,1]), 32, [32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's flat kernel array to (kROxkNE1xCHA, oE1xCHA)\n",
    "kRO, kNE1, srcCHA, dstCHA, oE1 = ker.shape\n",
    "ker_2D = np.reshape(ker, (kRO*kNE1*srcCHA, dstCHA*oE1), order='F')\n",
    "print(ker_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do the grappa recon by matrix multiplication\n",
    "RO = data.shape[0]\n",
    "E1 = data.shape[1]\n",
    "# grappa recon here!\n",
    "recon = np.dot(dataA, ker_2D)\n",
    "\n",
    "# fill the recon back to original kspace to fill missing dots\n",
    "res = grappa.recon_fill_back_kspace(recon, dataAInd, RO, E1)\n",
    "if (not fitItself):\n",
    "    res = np.add(res, data2D)\n",
    "\n",
    "# get the image\n",
    "im = transform.transform_kspace_to_image(res)\n",
    "im_combined = np.sum(im*np.conj(csm), axis=2)\n",
    "res = plot_image_array(np.abs(im_combined), 1, [8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grappa Recon as a NN\n",
    "\n",
    "First to remember, PyTorch does not support complex data type yet, so we need to modify Grappa recon process accordingly:\n",
    "![Grappa Recon as a NN!](images/GrappaNN.jpg)\n",
    "\n",
    "The real and imag parts of Grappa kernel are extracted and torch.nn.Linear layers are initliazed with Grappa weights. The reconstruction thus consists of two linear layers and add/subtract operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_r = np.real(A)\n",
    "A_i = np.imag(A)\n",
    "\n",
    "ker_2D_r = np.real(ker_2D)\n",
    "ker_2D_i = np.imag(ker_2D)\n",
    "\n",
    "dataA_r = np.real(dataA)\n",
    "dataA_i = np.imag(dataA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prove the concepts\n",
    "\n",
    "_, Din = A.shape\n",
    "_, H0 = B.shape\n",
    "\n",
    "with_bias = False\n",
    "input_layer_r = torch.nn.Linear(int(Din), int(H0), bias=with_bias)\n",
    "input_layer_i = torch.nn.Linear(int(Din), int(H0), bias=with_bias)\n",
    "\n",
    "input_layer_r.weight.data = torch.from_numpy(np.transpose(ker_2D_r, (1,0)))\n",
    "input_layer_i.weight.data = torch.from_numpy(np.transpose(ker_2D_i, (1,0)))\n",
    "\n",
    "r_r = input_layer_r(torch.from_numpy(dataA_r))\n",
    "i_i = input_layer_i(torch.from_numpy(dataA_i))\n",
    "r_i = input_layer_r(torch.from_numpy(dataA_i))\n",
    "i_r = input_layer_i(torch.from_numpy(dataA_r))\n",
    "\n",
    "C_r = r_r - i_i\n",
    "C_i = r_i + i_r\n",
    "\n",
    "recon = C_r.detach().numpy() + 1j * C_i.detach().numpy()\n",
    "\n",
    "res = grappa.recon_fill_back_kspace(recon, dataAInd, RO, E1)\n",
    "if (not fitItself):\n",
    "    res = np.add(res, data2D)\n",
    "\n",
    "# get the image\n",
    "im = transform.transform_kspace_to_image(res)\n",
    "im_combined = np.sum(im*np.conj(csm), axis=2)\n",
    "res = plot_image_array(np.abs(im_combined), 1, [8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's write a grappa recon NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrappaAI(nn.Module):\n",
    "    def __init__(self, Din, Dout, params):\n",
    "        \n",
    "        super(GrappaAI, self).__init__()\n",
    "\n",
    "        self.verbose = params['verbose']\n",
    "        self.with_bias = False\n",
    "        self.grappa_weights_r = params['grappa_weights_r']\n",
    "        self.grappa_weights_i = params['grappa_weights_i']\n",
    "        \n",
    "        # for real and imag\n",
    "        self.input_layer_r = torch.nn.Linear(int(Din/2), int(Dout/2), bias=self.with_bias)\n",
    "        self.input_layer_i = torch.nn.Linear(int(Din/2), int(Dout/2), bias=self.with_bias)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"    GrappaAI : input size (%d), output size (%d), with bias %s\" % (Din, Dout, self.with_bias))\n",
    "\n",
    "        print(\"---> Set grappa weights\")\n",
    "        self.input_layer_r.weight.data = self.grappa_weights_r\n",
    "        self.input_layer_i.weight.data = self.grappa_weights_i\n",
    "                \n",
    "    def forward(self, x):\n",
    "\n",
    "        # split x to real and img\n",
    "        M, N = x.shape\n",
    "\n",
    "        N_h = int(N/2)\n",
    "\n",
    "        x_r = x[:, 0:N_h]\n",
    "        x_i = x[:, N_h:N]\n",
    "\n",
    "        r_r = self.input_layer_r(x_r)\n",
    "        i_i = self.input_layer_i(x_i)\n",
    "\n",
    "        r_i = self.input_layer_r(x_i)\n",
    "        i_r = self.input_layer_i(x_r)\n",
    "\n",
    "        res_r = r_r - i_i\n",
    "        res_i = r_i + i_r\n",
    "\n",
    "        out = torch.cat([res_r, res_i], dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "\n",
    "params['verbose'] = True\n",
    "params['grappa_weights_r'] = torch.from_numpy(np.transpose(ker_2D_r, (1,0))).to(torch.float32)\n",
    "params['grappa_weights_i'] = torch.from_numpy(np.transpose(ker_2D_i, (1,0))).to(torch.float32)\n",
    "       \n",
    "# for real and imag parts\n",
    "Din = 2*A.shape[1]\n",
    "Dout = 2*B.shape[1]\n",
    "\n",
    "model = GrappaAI(Din, Dout, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to dataA\n",
    "dataA_NN = complex_2_real(dataA)\n",
    "print(\"dataA for NN is \", dataA_NN.shape)\n",
    "\n",
    "dataA_NN = torch.from_numpy(dataA_NN)\n",
    "dataA_NN = dataA_NN.to(torch.float32)\n",
    "\n",
    "recon_NN = model(dataA_NN)\n",
    "\n",
    "recon = recon_NN.detach().cpu().numpy()\n",
    "recon = real_2_complex(recon)\n",
    "print(\"Recon after NN is \", recon.shape)\n",
    "\n",
    "res = grappa.recon_fill_back_kspace(recon, dataAInd, RO, E1)\n",
    "if (not fitItself):\n",
    "    res = np.add(res, data2D)\n",
    "\n",
    "# get the image\n",
    "im = transform.transform_kspace_to_image(res)\n",
    "im_combined = np.sum(im*np.conj(csm), axis=2)\n",
    "res = plot_image_array(np.abs(im_combined), 1, [8, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Grappa.ai in Gadgetron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdin: is not a tty\n",
      "-bash: line 1: gadgetron_ismrmrd_client: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'gadgetron_ismrmrd_client -f ./data/meas_MID00349_FID09273_SNR_R3/meas_MID00349_FID09273_SNR_R3.h5 -c Generic_Cartesian_Grappa_AI.xml -a localhost -p 9002 -G grappa_ai -o ./data/meas_MID00349_FID09273_SNR_R3/grappa_ai_res.h5\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-246cb741acaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bash'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gadgetron_ismrmrd_client -f ./data/meas_MID00349_FID09273_SNR_R3/meas_MID00349_FID09273_SNR_R3.h5 -c Generic_Cartesian_Grappa_AI.xml -a localhost -p 9002 -G grappa_ai -o ./data/meas_MID00349_FID09273_SNR_R3/grappa_ai_res.h5\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2323\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2324\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[1;34m(line, cell)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# write a basic docstring:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\IPython\\core\\magics\\script.py\u001b[0m in \u001b[0;36mshebang\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'b'gadgetron_ismrmrd_client -f ./data/meas_MID00349_FID09273_SNR_R3/meas_MID00349_FID09273_SNR_R3.h5 -c Generic_Cartesian_Grappa_AI.xml -a localhost -p 9002 -G grappa_ai -o ./data/meas_MID00349_FID09273_SNR_R3/grappa_ai_res.h5\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gadgetron_ismrmrd_client -f ./data/meas_MID00349_FID09273_SNR_R3/meas_MID00349_FID09273_SNR_R3.h5 -c Generic_Cartesian_Grappa_AI.xml -a localhost -p 9002 -G grappa_ai -o ./data/meas_MID00349_FID09273_SNR_R3/grappa_ai_res.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
